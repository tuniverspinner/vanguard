# xAI Models Test Suite

This test suite validates the integration of new xAI models (`grok-code-fast-1` and `grok-4-fast`) into Vanguard.

## Quick Start

```bash
# Run mock tests (fast, no API calls)
./suites/run

# Run with real API validation (makes actual xAI API calls)
./suites/run --cost=true
```

**‚ö†Ô∏è  WARNING: `--cost=true` makes real API calls that cost real money!**
Set `XAI_API_KEY` environment variable before running cost tests.

## What These Tests Validate

### Cost Calculation Functions
- **Pricing Accuracy**: Validates that cost calculations match xAI's published pricing
- **Cache Logic**: Ensures cache read/write costs are calculated correctly
- **Edge Cases**: Tests zero tokens, large volumes, and overflow conditions

### Model Specifications
- **Context Windows**: 256K for grok-code-fast-1, 2M for grok-4-fast
- **Feature Support**: Image capabilities, prompt caching
- **Pricing Structure**: Input/output/cache pricing validation

## Model Pricing (Validated)

### grok-code-fast-1
- **Input**: $0.20 per 1M tokens
- **Output**: $1.50 per 1M tokens
- **Cache Reads**: $0.02 per 1M tokens
- **Cache Writes**: $0.00 (not charged by xAI)
- **Context Window**: 256,000 tokens
- **Use Case**: Optimized for coding workflows

### grok-4-fast
- **Input**: $0.20 per 1M tokens
- **Output**: $0.50 per 1M tokens
- **Cache Reads**: $0.05 per 1M tokens
- **Cache Writes**: $0.00 (not charged by xAI)
- **Context Window**: 2,000,000 tokens
- **Use Case**: Large codebase processing, output-heavy tasks

## Test Results Interpretation

### Expected Results
- **10/11 tests should pass** ‚úÖ
- **1 test currently fails** (cache comparison logic)

### Failing Test: Cache Comparison
**Test**: `shows grok-code-fast-1 advantage for cache-heavy tasks`

**Issue**: The test expects grok-code-fast-1 ($0.02 cache read pricing) to be cheaper than grok-4-fast ($0.05 cache read pricing) for cache-heavy workloads. However, calculations show grok-code-fast-1 at $0.0018 vs grok-4-fast at $0.00095.

**Possible Resolutions**:
1. **Fix Test Expectation**: If grok-4-fast should actually be cheaper for cache tasks
2. **Debug Calculation**: If there's an error in the cost calculation logic
3. **Update Pricing**: If xAI pricing has changed

## Cost Calculation Logic

The tests use `calculateApiCostOpenAI()` which follows this formula:

```typescript
// Non-cached tokens = total input - cache writes - cache reads
nonCachedTokens = totalInputTokens - cacheWriteTokens - cacheReadTokens

// Calculate costs
inputCost = nonCachedTokens * (inputPrice / 1_000_000)
cacheWriteCost = cacheWriteTokens * (cacheWritesPrice / 1_000_000)
cacheReadCost = cacheReadTokens * (cacheReadsPrice / 1_000_000)
outputCost = outputTokens * (outputPrice / 1_000_000)

totalCost = inputCost + cacheWriteCost + cacheReadCost + outputCost
```

## Test Categories

### ‚úÖ Cost Calculations (8 tests)
- Basic input/output pricing
- Cache token handling
- Large volume calculations
- Zero token edge cases

### ‚úÖ Model Validation (2 tests)
- Specification verification
- Pricing structure validation

### üéØ Real API Tests (Future)
- API connectivity validation
- Authentication testing
- Streaming response verification

## Integration Readiness

**Prerequisites for Model Integration**:
1. ‚úÖ All tests pass (11/11)
2. ‚úÖ Pricing validated against xAI documentation
3. ‚úÖ Cost calculations accurate
4. ‚úÖ Model specifications confirmed

**Next Steps After Tests Pass**:
1. Add models to `src/shared/api.ts`
2. Run TypeScript compilation check
3. Test model selection in UI
4. Validate end-to-end functionality

## Troubleshooting

### Common Issues
- **Failing cache test**: Check if xAI pricing assumptions are correct
- **Import errors**: Ensure Vitest is properly installed
- **Path resolution**: Check TypeScript path aliases in `vitest.config.ts`

### Debug Mode
```bash
# Run with verbose output
npx vitest run xai-models.test.ts --reporter=verbose

# Run specific test
npx vitest run xai-models.test.ts -t "cache comparison"
```

## Architecture Notes

- **Framework**: Vitest (3x faster than Mocha)
- **Environment**: Node.js with ESM support
- **Mock Strategy**: Pure function testing for deterministic results
- **Real API Mode**: Environment-variable controlled for safety

This test suite ensures safe, validated integration of new xAI models with comprehensive cost and functionality verification.
